{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "Education                    0.030622\n",
       "Mechanical Engineer          0.028680\n",
       "Electrical Engineering       0.028680\n",
       "Consultant                   0.027485\n",
       "Civil Engineer               0.027186\n",
       "Sales                        0.027186\n",
       "Management                   0.026962\n",
       "Human Resources              0.026888\n",
       "Digital Media                0.026738\n",
       "Accountant                   0.026141\n",
       "Java Developer               0.025991\n",
       "Building and Construction    0.025767\n",
       "Operations Manager           0.025767\n",
       "Architecture                 0.025693\n",
       "Testing                      0.025693\n",
       "Business Analyst             0.025394\n",
       "Aviation                     0.025394\n",
       "Finance                      0.025319\n",
       "SQL Developer                0.025245\n",
       "Public Relations             0.025170\n",
       "Health and Fitness           0.024796\n",
       "Arts                         0.024796\n",
       "Network Security Engineer    0.024647\n",
       "DotNet Developer             0.024572\n",
       "Apparel                      0.023900\n",
       "Banking                      0.023452\n",
       "Automobile                   0.023377\n",
       "Web Designing                0.023079\n",
       "SAP Developer                0.022705\n",
       "Data Science                 0.022332\n",
       "ETL Developer                0.021958\n",
       "Agriculture                  0.021884\n",
       "Advocate                     0.021734\n",
       "DevOps                       0.021585\n",
       "PMO                          0.021361\n",
       "Information Technology       0.020465\n",
       "Designing                    0.019270\n",
       "Database                     0.019195\n",
       "Python Developer             0.018523\n",
       "BPO                          0.015162\n",
       "React Developer              0.013593\n",
       "Food and Beverages           0.012099\n",
       "Blockchain                   0.003510\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "def load_data_set() : \n",
    "    return pd.read_csv(\"train.csv\")\n",
    "    \n",
    "data_set = load_data_set()\n",
    "data_set_valuecount = data_set['Category'].value_counts()\n",
    "data_set_valuecount.head()\n",
    "\n",
    "data_set.head()\n",
    "data_set[\"Category\"].value_counts()/len(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\n",
    "for train_idx,test_idx in split.split(data_set,data_set[\"Category\"]) : \n",
    "    strat_train_data = data_set.loc[train_idx]\n",
    "    strat_test_data = data_set.loc[test_idx]\n",
    "    \n",
    "strat_train_data[\"Category\"].value_counts() / len(data_set)\n",
    "strat_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_category = strat_train_data[\"Category\"].copy()\n",
    "strat_train_text = strat_train_data.drop([\"Category\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_text[\"Text\"] = strat_train_text[\"Text\"].str.lower()\n",
    "strat_train_text[\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "punctuation_pattern = r'[^\\w\\s$]'\n",
    "strat_train_text[\"Text\"] = strat_train_text[\"Text\"].str.replace(punctuation_pattern,'',regex=True)\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize_data(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc if not token.is_stop]\n",
    "\n",
    "strat_train_text[\"Tokens\"] = strat_train_text[\"Text\"].apply(tokenize_data)\n",
    "\n",
    "strat_train_text.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_data (text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc ]\n",
    "\n",
    "strat_train_text[\"Tokens\"] = strat_train_text[\"Text\"].apply(lemmatize_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub \n",
    "\n",
    "bert_preprocessor = hub.keraslayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "bert_model = hub.keraslayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\")\n",
    "\n",
    "def bert_vectorization(text):\n",
    "    pre_precessed_text = bert_preprocessor(text)\n",
    "    return bert_model(pre_precessed_text)[\"pooled_output\"]\n",
    "\n",
    "strat_train_text[\"Tokens\"] = strat_train_text[\"Tokens\"].apply(bert_vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight \n",
    "\n",
    "class_weight = compute_class_weight(class_weight='balanced',classes = np.unique(data_set[\"Category\"]),y=data_set[\"Category\"])\n",
    "class_weight_dict = dict(enumerate(class_weight))\n",
    "print(\"Class weights\", class_weight_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
